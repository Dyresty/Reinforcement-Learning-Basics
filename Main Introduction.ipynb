{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0daabe75-dafe-4afc-9ccf-6aa2f37108ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (2.5.0)\n",
      "Requirement already satisfied: gymnasium<1.1.0,>=0.29.1 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.20 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from stable-baselines3[extra]) (1.23.5)\n",
      "Requirement already satisfied: torch<3.0,>=2.3 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from stable-baselines3[extra]) (2.5.1)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from stable-baselines3[extra]) (3.1.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from stable-baselines3[extra]) (2.2.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from stable-baselines3[extra]) (3.10.1)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from stable-baselines3[extra]) (4.11.0.86)\n",
      "Requirement already satisfied: pygame in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from stable-baselines3[extra]) (2.6.1)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from stable-baselines3[extra]) (2.12.2)\n",
      "Requirement already satisfied: psutil in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from stable-baselines3[extra]) (7.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from stable-baselines3[extra]) (4.67.1)\n",
      "Requirement already satisfied: rich in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from stable-baselines3[extra]) (13.9.4)\n",
      "Requirement already satisfied: ale-py>=0.9.0 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from stable-baselines3[extra]) (0.10.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from stable-baselines3[extra]) (11.0.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from ale-py>=0.9.0->stable-baselines3[extra]) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from gymnasium<1.1.0,>=0.29.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.53.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.17.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.4.3)\n",
      "Requirement already satisfied: protobuf>=3.19.6 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (4.22.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.28.2)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.8.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.2.3)\n",
      "Requirement already satisfied: wheel>=0.26 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.45.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from sympy==1.13.1->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (4.56.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.4.8)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib->stable-baselines3[extra]) (23.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2025.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.19.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.2.8)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (1.3.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->stable-baselines3[extra]) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->stable-baselines3[extra]) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from requests<3,>=2.21.0->tensorboard>=2.9.1->stable-baselines3[extra]) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[extra]) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[extra]) (3.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5921ddc2-cfbe-4cda-9125-ebcfa90e2078",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install shimmy>=2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5a320ba-c63c-44d5-bf76-320d02a8e243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (1.0.0)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from gymnasium) (1.23.5)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from gymnasium) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from gymnasium) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from gymnasium) (0.0.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install gymnasium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4198d32-2778-4c39-83f5-deb2e5af34eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rocha\\appdata\\roaming\\python\\python310\\site-packages (from jinja2->torch) (2.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34991a7d-ecdb-462e-8126-e45c11601c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "CUDA Version: 12.1\n",
      "GPU Name: NVIDIA GeForce RTX 3060 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA Version: {torch.version.cuda}\")\n",
    "print(f\"GPU Name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'No GPU found'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9615a95-2856-4a29-a5a0-47ea4e81c7fd",
   "metadata": {},
   "source": [
    "## 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "db052a8a-4d18-4939-8667-14554945bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os #os library for defining paths\n",
    "import gymnasium as gym #openAI gym. Allows to build environments and work with preexisting environments easily. \n",
    "from stable_baselines3 import PPO #An Algorithm \n",
    "from stable_baselines3.common.vec_env import DummyVecEnv #Train model at multiple envs at same time, \n",
    "#vectorizing envs.\n",
    "from stable_baselines3.common.evaluation import evaluate_policy #Evaluate - Avg reward over \n",
    "#certain no of episodes, std dev\n",
    "#import matplotlib.pyplot as plt\n",
    "#from IPython import display\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef66cbe4-db37-49e9-b94b-932d36019421",
   "metadata": {},
   "source": [
    "## 2. Load Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "12342ad7-44f6-4269-81a5-ca85f84e8f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ecb78a7-5582-4434-9aef-bdb6bba5c847",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1: Score 56.0\n",
      "Episode 2: Score 19.0\n",
      "Episode 3: Score 16.0\n",
      "Episode 4: Score 18.0\n",
      "Episode 5: Score 19.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "episodes = 5\n",
    "scores = []  # Store all scores\n",
    "\n",
    "for episode in range(1, episodes + 1):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "    step = 0\n",
    "\n",
    "    while not done:\n",
    "        #For Displaying\n",
    "        frame = env.render()\n",
    "        if step % 15 == 0:\n",
    "            display.clear_output(wait=True)\n",
    "            plt.imshow(frame)\n",
    "            plt.axis(\"off\")\n",
    "            display.display(plt.gcf())\n",
    "            # Print scores once per update\n",
    "            print(\"\\n\".join([f\"Episode {ep}: Score {sc}\" for ep, sc in enumerate(scores, 1)]))\n",
    "\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, _, _ = env.step(action)\n",
    "        score += reward\n",
    "        step += 1\n",
    "\n",
    "    scores.append(score)  # Store the final score for this episode\n",
    "\n",
    "    # Print updated scores once after the episode ends\n",
    "    display.clear_output(wait=True)\n",
    "    plt.imshow(frame)\n",
    "    plt.axis(\"off\")\n",
    "    display.display(plt.gcf())\n",
    "    print(\"\\n\".join([f\"Episode {ep}: Score {sc}\" for ep, sc in enumerate(scores, 1)]))\n",
    "\n",
    "env.close()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "44f982ea-ae05-4c7f-ac09-e559ae59e7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1, Score: 15.0\n",
      "Episode: 2, Score: 23.0\n",
      "Episode: 3, Score: 10.0\n",
      "Episode: 4, Score: 43.0\n",
      "Episode: 5, Score: 43.0\n"
     ]
    }
   ],
   "source": [
    "episodes = 5\n",
    "\n",
    "for episode in range(1, episodes + 1):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        frame = env.render()\n",
    "\n",
    "        # Convert RGB to BGR (OpenCV uses BGR format)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Display using OpenCV\n",
    "        cv2.imshow(\"CartPole\", frame)\n",
    "        cv2.waitKey(20)  # 1ms delay\n",
    "\n",
    "        action = env.action_space.sample()\n",
    "        n_state, reward, done, _, _ = env.step(action)\n",
    "        score += reward\n",
    "\n",
    "    print(f'Episode: {episode}, Score: {score}')\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c68960a5-f671-4a72-8776-3faa50860fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3a7822f-3d36-4b62-af5f-b8d330186163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discrete(2)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(env.action_space)\n",
    "print(env.action_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdcd1bea-8dea-4f62-adde-727044298bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Box([-4.8000002e+00 -3.4028235e+38 -4.1887903e-01 -3.4028235e+38], [4.8000002e+00 3.4028235e+38 4.1887903e-01 3.4028235e+38], (4,), float32)\n",
      "[-1.3702348e+00  5.3782374e+37 -3.3781979e-02  3.0788986e+38]\n"
     ]
    }
   ],
   "source": [
    "print(env.observation_space)\n",
    "print(env.observation_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3037962-ee4a-48d1-95c6-f0627d70fab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5b54030b-1ace-4731-b21d-350a51a2f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3707ff12-914d-44f7-bdd3-2078211c2d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#env.step(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23298215-606a-4516-886a-ccc887b08c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-2.2199516e+00  2.2329586e+38  1.9532925e-01 -2.9656104e+38]\n"
     ]
    }
   ],
   "source": [
    "#print(env.observation_space.sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465d9371-4a89-4bd1-876a-d2858b50c556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb18ec92-268d-45bb-a220-0e0db7089600",
   "metadata": {},
   "source": [
    "## 3. Train an RL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ff1eed1-381a-4d5c-b162-40e2f22c09bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make directories for this /Training/Logs and /Training/Saved Models\n",
    "log_path = os.path.join('Training','Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ce295b72-0c0a-4eae-80cb-e5d31c548359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training\\\\Logs'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c32ca1ca-d9f7-4591-ae3e-95fa9f462e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "env = DummyVecEnv([lambda: env])\n",
    "#model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log = log_path)\n",
    "model = PPO(\"MlpPolicy\", env, verbose=1, tensorboard_log=\"log_path\", device=\"cpu\")\n",
    "#MlpPolicy - Multilayer Perceptron Policy\n",
    "#Stable Baselines 3 has three policy types - MlpPolicy, CnnPolicy, MultiInputPolicy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "74a0c8ef-4652-4dfc-8628-ccf78806768f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mInit signature:\u001b[0m\n",
       "\u001b[0mPPO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpolicy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstable_baselines3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mActorCriticPolicy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0menv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgymnasium\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEnv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mForwardRef\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'VecEnv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mlearning_rate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0003\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_steps\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2048\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mn_epochs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mgamma\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.99\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mgae_lambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.95\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mclip_range\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mclip_range_vf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mNoneType\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mnormalize_advantage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0ment_coef\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mvf_coef\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0muse_sde\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0msde_sample_freq\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrollout_buffer_class\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstable_baselines3\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuffers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRolloutBuffer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mrollout_buffer_kwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtarget_kl\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mstats_window_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mtensorboard_log\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpolicy_kwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mseed\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0m_init_setup_model\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mSource:\u001b[0m        \n",
       "\u001b[1;32mclass\u001b[0m \u001b[0mPPO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOnPolicyAlgorithm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;34m\"\"\"\n",
       "    Proximal Policy Optimization algorithm (PPO) (clip version)\n",
       "\n",
       "    Paper: https://arxiv.org/abs/1707.06347\n",
       "    Code: This implementation borrows code from OpenAI Spinning Up (https://github.com/openai/spinningup/)\n",
       "    https://github.com/ikostrikov/pytorch-a2c-ppo-acktr-gail and\n",
       "    Stable Baselines (PPO2 from https://github.com/hill-a/stable-baselines)\n",
       "\n",
       "    Introduction to PPO: https://spinningup.openai.com/en/latest/algorithms/ppo.html\n",
       "\n",
       "    :param policy: The policy model to use (MlpPolicy, CnnPolicy, ...)\n",
       "    :param env: The environment to learn from (if registered in Gym, can be str)\n",
       "    :param learning_rate: The learning rate, it can be a function\n",
       "        of the current progress remaining (from 1 to 0)\n",
       "    :param n_steps: The number of steps to run for each environment per update\n",
       "        (i.e. rollout buffer size is n_steps * n_envs where n_envs is number of environment copies running in parallel)\n",
       "        NOTE: n_steps * n_envs must be greater than 1 (because of the advantage normalization)\n",
       "        See https://github.com/pytorch/pytorch/issues/29372\n",
       "    :param batch_size: Minibatch size\n",
       "    :param n_epochs: Number of epoch when optimizing the surrogate loss\n",
       "    :param gamma: Discount factor\n",
       "    :param gae_lambda: Factor for trade-off of bias vs variance for Generalized Advantage Estimator\n",
       "    :param clip_range: Clipping parameter, it can be a function of the current progress\n",
       "        remaining (from 1 to 0).\n",
       "    :param clip_range_vf: Clipping parameter for the value function,\n",
       "        it can be a function of the current progress remaining (from 1 to 0).\n",
       "        This is a parameter specific to the OpenAI implementation. If None is passed (default),\n",
       "        no clipping will be done on the value function.\n",
       "        IMPORTANT: this clipping depends on the reward scaling.\n",
       "    :param normalize_advantage: Whether to normalize or not the advantage\n",
       "    :param ent_coef: Entropy coefficient for the loss calculation\n",
       "    :param vf_coef: Value function coefficient for the loss calculation\n",
       "    :param max_grad_norm: The maximum value for the gradient clipping\n",
       "    :param use_sde: Whether to use generalized State Dependent Exploration (gSDE)\n",
       "        instead of action noise exploration (default: False)\n",
       "    :param sde_sample_freq: Sample a new noise matrix every n steps when using gSDE\n",
       "        Default: -1 (only sample at the beginning of the rollout)\n",
       "    :param rollout_buffer_class: Rollout buffer class to use. If ``None``, it will be automatically selected.\n",
       "    :param rollout_buffer_kwargs: Keyword arguments to pass to the rollout buffer on creation\n",
       "    :param target_kl: Limit the KL divergence between updates,\n",
       "        because the clipping is not enough to prevent large update\n",
       "        see issue #213 (cf https://github.com/hill-a/stable-baselines/issues/213)\n",
       "        By default, there is no limit on the kl div.\n",
       "    :param stats_window_size: Window size for the rollout logging, specifying the number of episodes to average\n",
       "        the reported success rate, mean episode length, and mean reward over\n",
       "    :param tensorboard_log: the log location for tensorboard (if None, no logging)\n",
       "    :param policy_kwargs: additional arguments to be passed to the policy on creation. See :ref:`ppo_policies`\n",
       "    :param verbose: Verbosity level: 0 for no output, 1 for info messages (such as device or wrappers used), 2 for\n",
       "        debug messages\n",
       "    :param seed: Seed for the pseudo random generators\n",
       "    :param device: Device (cpu, cuda, ...) on which the code should be run.\n",
       "        Setting it to auto, the code will be run on the GPU if possible.\n",
       "    :param _init_setup_model: Whether or not to build the network at the creation of the instance\n",
       "    \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mpolicy_aliases\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mClassVar\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBasePolicy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;34m\"MlpPolicy\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mActorCriticPolicy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;34m\"CnnPolicy\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mActorCriticCnnPolicy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;34m\"MultiInputPolicy\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMultiInputActorCriticPolicy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m}\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mpolicy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mActorCriticPolicy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0menv\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mGymEnv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mlearning_rate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSchedule\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3e-4\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mn_steps\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2048\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mn_epochs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mgamma\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.99\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mgae_lambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.95\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mclip_range\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSchedule\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mclip_range_vf\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSchedule\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mnormalize_advantage\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0ment_coef\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mvf_coef\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0muse_sde\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0msde_sample_freq\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mrollout_buffer_class\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mRolloutBuffer\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mrollout_buffer_kwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mtarget_kl\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mstats_window_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mtensorboard_log\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mpolicy_kwargs\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mverbose\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mseed\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mdevice\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"auto\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0m_init_setup_model\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mpolicy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mn_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mgae_lambda\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgae_lambda\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0ment_coef\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ment_coef\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mvf_coef\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvf_coef\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0muse_sde\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_sde\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0msde_sample_freq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msde_sample_freq\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mrollout_buffer_class\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrollout_buffer_class\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mrollout_buffer_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrollout_buffer_kwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mstats_window_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstats_window_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mtensorboard_log\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtensorboard_log\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mpolicy_kwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpolicy_kwargs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0m_init_setup_model\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0msupported_action_spaces\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mspaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mspaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDiscrete\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mspaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiDiscrete\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mspaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMultiBinary\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Sanity check, otherwise it will lead to noisy gradient and NaN\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# because of the advantage normalization\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mnormalize_advantage\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32massert\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mbatch_size\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"`batch_size` must be greater than 1. See https://github.com/DLR-RM/stable-baselines3/issues/440\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# Check that `n_steps * n_envs > 1` to avoid NaN\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# when doing advantage normalization\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mbuffer_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_envs\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32massert\u001b[0m \u001b[0mbuffer_size\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mnot\u001b[0m \u001b[0mnormalize_advantage\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf\"`n_steps * n_envs` must be greater than 1. Currently n_steps={self.n_steps} and n_envs={self.env.num_envs}\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# Check that the rollout buffer size is a multiple of the mini-batch size\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0muntruncated_batches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuffer_size\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0mbuffer_size\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;34mf\"You have specified a mini-batch size of {batch_size},\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;34mf\" but because the `RolloutBuffer` is of size `n_steps * n_envs = {buffer_size}`,\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;34mf\" after every {untruncated_batches} untruncated mini-batches,\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;34mf\" there will be a truncated mini-batch of size {buffer_size % batch_size}\\n\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;34mf\"We recommend using a `batch_size` that is a factor of `n_steps * n_envs`.\\n\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;34mf\"Info: (n_steps={self.n_steps} and n_envs={self.env.num_envs})\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclip_range\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_range_vf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclip_range_vf\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_advantage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize_advantage\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_kl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtarget_kl\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0m_init_setup_model\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0m_setup_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setup_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Initialize schedules for policy/value clipping\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_schedule_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_range_vf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_range_vf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_range_vf\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"`clip_range_vf` must be positive, \"\u001b[0m \u001b[1;34m\"pass `None` to deactivate vf clipping\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_range_vf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_schedule_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_range_vf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;34m\"\"\"\n",
       "        Update policy using the currently gathered rollout buffer.\n",
       "        \"\"\"\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Switch to train mode (this affects batch norm / dropout)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_training_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Update optimizer learning rate\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_learning_rate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Compute current clip range\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mclip_range\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_range\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current_progress_remaining\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[operator]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Optional: clip range for the value function\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_range_vf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mclip_range_vf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_range_vf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_current_progress_remaining\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[operator]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mentropy_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mpg_losses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mclip_fractions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mcontinue_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# train for n_epochs epochs\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mapprox_kl_divs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;31m# Do a complete pass on the rollout buffer\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mfor\u001b[0m \u001b[0mrollout_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrollout_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspaces\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDiscrete\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;31m# Convert discrete action from float to long\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mactions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrollout_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlog_prob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentropy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_actions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrollout_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservations\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;31m# Normalize advantage\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0madvantages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrollout_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madvantages\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;31m# Normalization does not make sense if mini batchsize == 1, see GH issue #325\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormalize_advantage\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0madvantages\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0madvantages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0madvantages\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0madvantages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0madvantages\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1e-8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;31m# ratio between old and new policy, should be one at the first iteration\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_prob\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mrollout_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mold_log_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;31m# clipped surrogate loss\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mpolicy_loss_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madvantages\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mratio\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mpolicy_loss_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0madvantages\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mclip_range\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mclip_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mpolicy_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolicy_loss_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicy_loss_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;31m# Logging\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mpg_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpolicy_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mclip_fraction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratio\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mclip_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mclip_fractions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip_fraction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_range_vf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;31m# No clipping\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mvalues_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;31m# Clip the difference between old and new value\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;31m# NOTE: this depends on the reward scaling\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mvalues_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrollout_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mold_values\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclamp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[0mvalues\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mrollout_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mold_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mclip_range_vf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip_range_vf\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;31m# Value loss using the TD(gae_lambda) target\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mvalue_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrollout_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mvalue_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;31m# Entropy loss favor exploration\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0mentropy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;31m# Approximate entropy when no analytical form\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mentropy_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mentropy_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentropy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mentropy_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentropy_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpolicy_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0ment_coef\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mentropy_loss\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvf_coef\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mvalue_loss\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;31m# Calculate approximate form of reverse KL Divergence for early stopping\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;31m# see issue #417: https://github.com/DLR-RM/stable-baselines3/issues/417\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;31m# and discussion in PR #419: https://github.com/DLR-RM/stable-baselines3/pull/419\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;31m# and Schulman blog: http://joschu.net/blog/kl-approx.html\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mwith\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mlog_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlog_prob\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mrollout_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mold_log_prob\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mapprox_kl_div\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_ratio\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlog_ratio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mapprox_kl_divs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapprox_kl_div\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_kl\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mapprox_kl_div\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1.5\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_kl\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[0mcontinue_training\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                        \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Early stopping at step {epoch} due to reaching max kl: {approx_kl_div:.2f}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                    \u001b[1;32mbreak\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;31m# Optimization step\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;31m# Clip grad norm\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_updates\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontinue_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m                \u001b[1;32mbreak\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mexplained_var\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplained_variance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrollout_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;31m# Logs\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train/entropy_loss\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mentropy_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train/policy_gradient_loss\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpg_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train/value_loss\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train/approx_kl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapprox_kl_divs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train/clip_fraction\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclip_fractions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train/loss\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train/explained_variance\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexplained_var\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"log_std\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train/std\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mth\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_std\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train/n_updates\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_updates\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"tensorboard\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train/clip_range\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip_range\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_range_vf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"train/clip_range_vf\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclip_range_vf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;32mdef\u001b[0m \u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mself\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSelfPPO\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMaybeCallback\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mlog_interval\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mtb_log_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"PPO\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mreset_num_timesteps\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[0mprogress_bar\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mSelfPPO\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mlog_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mtb_log_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtb_log_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mreset_num_timesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset_num_timesteps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m            \u001b[0mprogress_bar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress_bar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m        \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mFile:\u001b[0m           c:\\users\\rocha\\anaconda3\\envs\\py310_env\\lib\\site-packages\\stable_baselines3\\ppo\\ppo.py\n",
       "\u001b[1;31mType:\u001b[0m           ABCMeta\n",
       "\u001b[1;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PPO??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5349cf3a-155e-4bff-a84b-43d0dc8413ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to log_path\\PPO_2\n",
      "-----------------------------\n",
      "| time/              |      |\n",
      "|    fps             | 1530 |\n",
      "|    iterations      | 1    |\n",
      "|    time_elapsed    | 1    |\n",
      "|    total_timesteps | 2048 |\n",
      "-----------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 946        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 4          |\n",
      "|    total_timesteps      | 4096       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01061619 |\n",
      "|    clip_fraction        | 0.137      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.569     |\n",
      "|    explained_variance   | 0.918      |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.389      |\n",
      "|    n_updates            | 110        |\n",
      "|    policy_gradient_loss | -0.0188    |\n",
      "|    value_loss           | 9.26       |\n",
      "----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 835          |\n",
      "|    iterations           | 3            |\n",
      "|    time_elapsed         | 7            |\n",
      "|    total_timesteps      | 6144         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0034258312 |\n",
      "|    clip_fraction        | 0.0225       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.535       |\n",
      "|    explained_variance   | 0.0108       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 14           |\n",
      "|    n_updates            | 120          |\n",
      "|    policy_gradient_loss | -0.00218     |\n",
      "|    value_loss           | 44.7         |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 790         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002972734 |\n",
      "|    clip_fraction        | 0.0344      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.523      |\n",
      "|    explained_variance   | 0.627       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.336       |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.000888   |\n",
      "|    value_loss           | 3.95        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 782         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015338412 |\n",
      "|    clip_fraction        | 0.178       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.518      |\n",
      "|    explained_variance   | 0.828       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.51        |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    value_loss           | 2.37        |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| time/                   |            |\n",
      "|    fps                  | 777        |\n",
      "|    iterations           | 6          |\n",
      "|    time_elapsed         | 15         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00781552 |\n",
      "|    clip_fraction        | 0.0683     |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -0.509     |\n",
      "|    explained_variance   | 0.0744     |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 0.0485     |\n",
      "|    n_updates            | 150        |\n",
      "|    policy_gradient_loss | -0.0042    |\n",
      "|    value_loss           | 1.19       |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 774         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 18          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.004593865 |\n",
      "|    clip_fraction        | 0.0226      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -0.5        |\n",
      "|    explained_variance   | -0.0489     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0364      |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.00022    |\n",
      "|    value_loss           | 0.709       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 767          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0038233132 |\n",
      "|    clip_fraction        | 0.0157       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.517       |\n",
      "|    explained_variance   | 0.154        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0331       |\n",
      "|    n_updates            | 170          |\n",
      "|    policy_gradient_loss | 0.00072      |\n",
      "|    value_loss           | 0.476        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 764          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0022004226 |\n",
      "|    clip_fraction        | 0.014        |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.493       |\n",
      "|    explained_variance   | 0.146        |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.0156       |\n",
      "|    n_updates            | 180          |\n",
      "|    policy_gradient_loss | 0.000498     |\n",
      "|    value_loss           | 0.292        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 763          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 26           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0054340167 |\n",
      "|    clip_fraction        | 0.0661       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -0.491       |\n",
      "|    explained_variance   | 0.0797       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | -0.00252     |\n",
      "|    n_updates            | 190          |\n",
      "|    policy_gradient_loss | -0.00492     |\n",
      "|    value_loss           | 0.174        |\n",
      "------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x1c31756bfd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=20000)\n",
    "#Timestamps - For a simple environment lower number of timestamps is okay,\n",
    "#    but must be increased for more sophisticated environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f40469-80c0-41e9-9520-e34e6a099f50",
   "metadata": {},
   "source": [
    "## 4. Save and Reload Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c761504a-9f5b-4fa0-a80f-97bdf93d4d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PPO_Path = os.path.join('Training','Saved Models','PPO_Model_Cartpole')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c28eb1bf-0606-460b-8db2-60f680b94d7b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39msave(PPO_Path)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "model.save(PPO_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910ceff0-cbfc-45f5-9396-ca52f30d3f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8aff4894-6eb4-48bd-b67a-2b876ecda053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training\\\\Saved Models\\\\PPO_Model_Cartpole'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PPO_Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "01c00cb9-66bd-45b1-82d4-29700685a607",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n"
     ]
    }
   ],
   "source": [
    "model = PPO.load(PPO_Path, env=env, device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dae1c1-6554-45e2-bafe-4dbe06ddfa94",
   "metadata": {},
   "source": [
    "## 5. Testing and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee0b7b8-f52b-4763-8f20-5bb8d8a891b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of episodes to evaluate\n",
    "n_eval_episodes = 10\n",
    "\n",
    "# Run evaluation with OpenCV visualization\n",
    "for episode in range(n_eval_episodes):\n",
    "    state, _ = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        # Render the frame\n",
    "        frame = env.render()\n",
    "\n",
    "        # Convert RGB to BGR for OpenCV\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Display the frame using OpenCV\n",
    "        cv2.imshow(\"CartPole\", frame)\n",
    "        #cv2.waitKey(30)  # Wait 1ms to allow smooth rendering\n",
    "\n",
    "        # Select an action using the trained model\n",
    "        action, _ = model.predict(state)\n",
    "\n",
    "        # Take a step in the environment\n",
    "        state, reward, done, info, _ = env.step(action)\n",
    "        score += reward\n",
    "\n",
    "    print(f\"Episode {episode + 1}: Score = {score}\")\n",
    "\n",
    "# Close OpenCV window\n",
    "cv2.destroyAllWindows()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c3047a3-e692-4211-9473-d66d88556e09",
   "metadata": {},
   "source": [
    "## 6. Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2f7ad0-e2be-462e-b8df-5c3ebbaa18b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "episodes = 5\n",
    "\n",
    "for episode in range(1, episodes + 1):\n",
    "    obs = env.reset()\n",
    "    done = False\n",
    "    score = 0\n",
    "\n",
    "    while not done:\n",
    "        \n",
    "        frame = env.render()\n",
    "        # Convert RGB to BGR (OpenCV uses BGR format)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_RGB2BGR)\n",
    "        # Display using OpenCV\n",
    "        cv2.imshow(\"CartPole\", frame)\n",
    "        cv2.waitKey(20)  # 1ms delay\n",
    "\n",
    "        action, _ = model.predict(obs)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "        score += reward\n",
    "\n",
    "    print(f'Episode: {episode}, Score: {score}')\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15ea1280-7b2d-4b7c-9929-6a8575a43782",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64aa1a3d-ca28-4beb-baad-5815780c864d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c35ad-161f-471d-a977-b9433d133a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2854447-ea73-4212-bc10-839f8f658793",
   "metadata": {},
   "outputs": [],
   "source": [
    "action,_ = model.predict(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24a3ed1-23ac-41c8-8900-0f1d8c3614be",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0149163-c791-4093-8984-a120f64ba53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "env.step(action)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723df121-fb6b-4d89-ae99-4ccf1cebf9ab",
   "metadata": {},
   "source": [
    "## 7. Viewing Logs in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4ab3efd-f653-49d9-b709-67a9d4fc9dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training','Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02c725ab-20de-4e4f-ac8c-5c8d378f8f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_log_path = os.path.join(log_path, 'PPO_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e397684-b284-47fc-996d-b127f8049d98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Training\\\\Logs\\\\PPO_2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_log_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bcf4d8c-df48-46c8-ba77-c8f5f22933e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!tensorboard --logdir = training_log_path\n",
    "#(py310_env) C:\\Users\\rocha\\Reinforcement Learning>python -m tensorboard.main --logdir=log_path\\PPO_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd1f685-a7fd-4b9f-8cfe-20524867cd3f",
   "metadata": {},
   "source": [
    "## 8. Adding a callback to the training Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04099b84-d911-45b5-929d-1b99f4bb8649",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Need to import additional dependencies \n",
    "from stable_baselines3.common.callbacks import EvalCallback, StopTrainingOnRewardThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c05a478-7e75-44fa-a918-b4b6d31b9736",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join(\"Training\",\"Saved Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7c199b39-f875-4bf2-99bc-f1ffdfa135f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m stop_callback \u001b[38;5;241m=\u001b[39m StopTrainingOnRewardThreshold(reward_threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m450\u001b[39m, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m eval_callback \u001b[38;5;241m=\u001b[39m EvalCallback(\u001b[43menv\u001b[49m, \n\u001b[0;32m      3\u001b[0m                              callback_on_new_best \u001b[38;5;241m=\u001b[39m stop_callback,\n\u001b[0;32m      4\u001b[0m                              eval_freq \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m,\n\u001b[0;32m      5\u001b[0m                              best_model_save_path\u001b[38;5;241m=\u001b[39msave_path,\n\u001b[0;32m      6\u001b[0m                              verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "stop_callback = StopTrainingOnRewardThreshold(reward_threshold = 450, verbose = 1)\n",
    "eval_callback = EvalCallback(env, \n",
    "                             callback_on_new_best = stop_callback,\n",
    "                             eval_freq = 1000,\n",
    "                             best_model_save_path=save_path,\n",
    "                             verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27cd45c-eef0-4bff-8245-97c6a9ed17f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f2b961-efaa-4f3e-9ef0-5b02a50ba8d4",
   "metadata": {},
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5324cf1c-1273-4d02-9f4f-94c6f2e95680",
   "metadata": {},
   "source": [
    "## 9. Changing Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7373d97-fd5d-45cf-bdca-5d341cbf05f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arch = [dict(pi=[128,128,128,128],vf=[128,128,128,128])]\n",
    "#vf - value function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e85ea89c-74d9-4090-8ecc-f6ef63170396",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'log_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m PPO(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMlpPolicy\u001b[39m\u001b[38;5;124m'\u001b[39m, env, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, tensorboard_log\u001b[38;5;241m=\u001b[39m\u001b[43mlog_path\u001b[49m, policy_kwargs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnet_arch\u001b[39m\u001b[38;5;124m'\u001b[39m:net_arch})\n",
      "\u001b[1;31mNameError\u001b[0m: name 'log_path' is not defined"
     ]
    }
   ],
   "source": [
    "model = PPO('MlpPolicy', env, verbose=1, tensorboard_log=log_path, policy_kwargs={'net_arch':net_arch})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "738d8dc2-d132-47a3-8c41-0d12e7dca54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000, callback=eval_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da11f85-ee91-4c82-a157-ac2fd68a8388",
   "metadata": {},
   "source": [
    "## 10. Using an Alternate Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fedae8-870d-4bcb-9ed3-a2daf7987098",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3 import DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423b873d-9ee7-4264-8e36-e7d999c03c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DQN('MlpPolicy', env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018af8b3-8f70-47b6-ae24-8fe9fd899d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.learn(total_timesteps=20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07ed040-39e7-423f-af69-a73aa5e161b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also remember for loading\n",
    "DQN.load(...)\n",
    "#instead of PPO.load(...)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
